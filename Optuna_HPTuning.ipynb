{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb47c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load balanced dataset\n",
    "file_path = 'diabetes_binary_5050split_health_indicators_BRFSS2015.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#Define selected features and target variable\n",
    "selected_features = ['HighBP', 'HighChol', 'Stroke', 'HeartDiseaseorAttack', \n",
    "                     'PhysActivity', 'DiffWalk', 'BMI', 'GenHlth', 'Age', 'Income']\n",
    "target_variable = 'Diabetes_binary'  \n",
    "X = data[selected_features]\n",
    "y = data[target_variable]\n",
    "\n",
    "#80/20 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "best_results = {}\n",
    "\n",
    "#Optuna objective function\n",
    "def objective(trial):\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"RandomForest\", \"DecisionTree\", \"XGBoost\", \"LogisticRegression\"])\n",
    "    if model_name == \"RandomForest\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "        bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            bootstrap=bootstrap,\n",
    "            random_state=100,\n",
    "        )\n",
    "    \n",
    "    elif model_name == \"DecisionTree\":\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "        criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            criterion=criterion,\n",
    "            random_state=100,\n",
    "        )\n",
    "\n",
    "    elif model_name == \"XGBoost\":\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            random_state=100,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "        )\n",
    "\n",
    "    elif model_name == \"LogisticRegression\":\n",
    "        C = trial.suggest_float(\"C\", 0.01, 10.0, log=True)\n",
    "        penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"])\n",
    "        solver = trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"])\n",
    "        model = LogisticRegression(\n",
    "            C=C,\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            random_state=100,\n",
    "            max_iter=1000,\n",
    "        )\n",
    "\n",
    "    #Explore 3 CV folds for each model \n",
    "    scoring = {\"accuracy\": \"accuracy\", \"f1\": make_scorer(f1_score)}\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=3, scoring=make_scorer(f1_score))\n",
    "    mean_accuracy = scores.mean()\n",
    "    mean_f1 = f1_scores.mean()\n",
    "\n",
    "    if model_name not in best_results or mean_accuracy > best_results[model_name][\"accuracy\"]:\n",
    "        best_results[model_name] = {\n",
    "            \"accuracy\": mean_accuracy,\n",
    "            \"f1\": mean_f1,\n",
    "            \"hyperparameters\": trial.params,\n",
    "        }\n",
    "\n",
    "    #Need to return optuna maximized hyperparameters and best model\n",
    "    return mean_accuracy \n",
    "\n",
    "#Run Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "#Display the best results for each model\n",
    "print(\"Optimal Results for Each Model:\")\n",
    "for model_name, results in best_results.items():\n",
    "    print(\"Model:\", model_name)\n",
    "    print(\"Best Accuracy:\", results['accuracy'])\n",
    "    print(\"Best Hyperparams:\", results['hyperparameters'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
